<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>[paper review] Fairness and Interactive Performance of O(1) and CFS Linux Kernel Schedulerss - Chaosmatrix</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="[paper review] Fairness and Interactive Performance of O(1) and CFS Linux Kernel Schedulerss">
<meta itemprop="description" content="Abstract For both medium and high load, CFS has higher average latency (5ms ~ 10ms) than O(1). The greater the load, the greater average latency. CFS parameters also has an impact on the average / tail latency. The nice value also has impact of CFS. The lower nice value, the greater time slice. The nice value also has impact of O(1). Review paper: Fairness and interactive performance of O(1) and CFS Linux kernel schedulers"><meta itemprop="datePublished" content="2022-09-01T21:05:18+08:00" />
<meta itemprop="dateModified" content="2022-09-01T21:05:18+08:00" />
<meta itemprop="wordCount" content="789">
<meta itemprop="keywords" content="paper-review,linux," /><meta property="og:title" content="[paper review] Fairness and Interactive Performance of O(1) and CFS Linux Kernel Schedulerss" />
<meta property="og:description" content="Abstract For both medium and high load, CFS has higher average latency (5ms ~ 10ms) than O(1). The greater the load, the greater average latency. CFS parameters also has an impact on the average / tail latency. The nice value also has impact of CFS. The lower nice value, the greater time slice. The nice value also has impact of O(1). Review paper: Fairness and interactive performance of O(1) and CFS Linux kernel schedulers" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chaosmatrix.github.io/blog/paper-review_fairness_and_interactive_performance_of_o1_and_cfs_linux_kernel_schedulers/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2022-09-01T21:05:18+08:00" />
<meta property="article:modified_time" content="2022-09-01T21:05:18+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[paper review] Fairness and Interactive Performance of O(1) and CFS Linux Kernel Schedulerss"/>
<meta name="twitter:description" content="Abstract For both medium and high load, CFS has higher average latency (5ms ~ 10ms) than O(1). The greater the load, the greater average latency. CFS parameters also has an impact on the average / tail latency. The nice value also has impact of CFS. The lower nice value, the greater time slice. The nice value also has impact of O(1). Review paper: Fairness and interactive performance of O(1) and CFS Linux kernel schedulers"/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://chaosmatrix.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://chaosmatrix.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://chaosmatrix.github.io/css/dark.css" />

	<script src="https://chaosmatrix.github.io/js/feather.min.js"></script>
	
		<script src="https://chaosmatrix.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
		<div class="avatar">
			<a href="https://chaosmatrix.github.io/">
				<img src="https://avatars.githubusercontent.com/u/37551759?v=4" alt="Chaosmatrix" />
			</a>
		</div>
	
	<h1 class="site-title"><a href="https://chaosmatrix.github.io/">Chaosmatrix</a></h1>
	<div class="site-description"><p>Thoughts come and go, words stay eternal</p><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/chaosmatrix" title="Github"><i data-feather="github"></i></a></li><li><a href="#" class="scheme-toggle" id="scheme-toggle"></a></li></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/blog">Blog</a>
			</li>
			
			<li>
				<a href="/wasm">Wasm</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">01</span>
							<span class="rest">Sep 2022</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">[paper review] Fairness and Interactive Performance of O(1) and CFS Linux Kernel Schedulerss</h1>
				</div>
			</div>
					
			<div class="markdown">
				<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="/js/mathjax-v3-es5-tex-svg.js">
</script>
<h2 id="abstract">Abstract</h2>
<ol>
<li>For both medium and high load, <strong>CFS</strong> has higher average latency (5ms ~ 10ms) than <strong>O(1)</strong>.</li>
<li>The greater the load, the greater average latency.</li>
<li>CFS parameters also has an impact on the average / tail latency.</li>
<li>The nice value also has impact of CFS. The lower nice value, the greater time slice.</li>
<li>The nice value also has impact of <strong>O(1)</strong>.</li>
</ol>
<h2 id="review">Review</h2>
<p>paper: <a href="https://ieeexplore.ieee.org/document/4631872">Fairness and interactive performance of O(1) and CFS Linux kernel schedulers</a></p>
<p>The testing result is base on the workload of linux desktop, not the workload of server.</p>
<hr>
<blockquote>
<p>The design goals of CFS are to provide fair CPU resource allocation among executing tasks without sacrificing interactive performance.</p>
</blockquote>
<p><strong>O(1)</strong></p>
<blockquote>
<p>&hellip; static priorities corresponds to a nice value &hellip; from -20 (highest) to 19 (lowest) &hellip;</p>
</blockquote>
<blockquote>
<p>Each task is allocated a base time slice based on its static priority/nice value using the equation:</p>
</blockquote>
<div>
<p>$$\begin{align*}
\large
Base \space Time \space Slice \space (ms) \space = \lbrace_{if \space static \space priority \space \geqslant \space 120 \space (140-static \space priority) \space \times \space 5}^{if \space static \space priority \space &lt; \space 120 \space (140-static \space priority) \space \times \space 20}
\end{align*}$$</p>
</div>
<p><strong>CFS</strong></p>
<blockquote>
<p>&hellip; was designed to provide good interactive performance while maximizing overall CPU utilization. Even during high load, the interactivity shall be maintained.</p>
</blockquote>
<p><strong>Fairness Test and Result</strong></p>
<blockquote>
<p>In the O(1) scheduler, some children finish executing faster than others.</p>
</blockquote>
<blockquote>
<p>&hellip; CFS scheduler distributes its CPU time among each tasks in a fairer manner compared to O(1) scheduler.</p>
</blockquote>
<p><strong>Interactivity Test and Result</strong></p>
<blockquote>
<p>For both medium and high load, the interactive task has lower latencies when running on O(1). Although CFS has higher average latency, the latency is well below humanâ€™s reaction time to visual stimulus, which is 180 to 200ms.</p>
</blockquote>
<blockquote>
<p>CFS scheduler has lower maximum latency recorded in all three types of background loads.</p>
</blockquote>
<hr>
<h2 id="in-real-work">In Real Work</h2>
<h3 id="basic">Basic</h3>
<h5 id="1-cfs-parameters">1. CFS parameters</h5>
<ul>
<li><strong>cpu.cfs_period_us:</strong> the length of period</li>
<li><strong>cpu.cfs_quota_us:</strong> run-time within period</li>
<li><strong>cpu.cfs_burst_us:</strong> maximum accumulated run-time</li>
</ul>
<h5 id="2-cfs-throttling-statistics">2. CFS Throttling Statistics</h5>
<ul>
<li><strong>cpu.stat.nr_periods:</strong> Number of enforcement intervals that have elapsed.</li>
<li><strong>cpu.stat.nr_throttled:</strong> Number of times the group has been throttled/limited.</li>
<li><strong>cpu.stat.throttled_time:</strong> The total time duration (in nanoseconds) for which entities of the group have been throttled.</li>
<li><strong>cpu.stat.nr_bursts:</strong> Number of periods burst occurs.</li>
<li><strong>cpu.stat.burst_time:</strong> Cumulative wall-time (in nanoseconds) that any CPUs has used above quota in respective periods.</li>
</ul>
<h5 id="3-how-cfs-work">3. How CFS Work</h5>
<p><strong>Pseudocode How CFS Work (without cpu.cfs_burst_us):</strong></p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#00f"># simulate a process executing under CFS
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>
</span></span><span style="display:flex;"><span><span style="color:#00f">while</span> process_need_cpu_us &gt; 0 {
</span></span><span style="display:flex;"><span>	process_need_cpu_us -= cpu.cfs_quota_us
</span></span><span style="display:flex;"><span>	<span style="color:#00f">if</span> process_need_cpu_us &gt; 0 {
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># cfs cpu.stat
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		cpu.stat.nr_periods++
</span></span><span style="display:flex;"><span>		cpu.stat.nr_throttled++
</span></span><span style="display:flex;"><span>		cpu.stat.throttled_time += (cpu.cfs_period_us - cpu.cfs_quota_us) * 1000
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># wait next period
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		sleep(cpu.cfs_period_us - cpu.cfs_quota_us)
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><strong>Pseudocode How CFS Work (with cpu.cfs_burst_us):</strong></p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#00f"># simulate a process executing under CFS
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>
</span></span><span style="display:flex;"><span>curr_cpu.cfs_burst_us = cpu.cfs_quota_us
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">while</span> process_need_cpu_us &gt; 0 {
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	process_need_cpu_us -= cpu.cfs_quota_us
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#00f">if</span> process_need_cpu_us &gt; 0 &amp;&amp; curr_cpu.cfs_burst_us &gt; cpu.cfs_quota_us {
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># trigger burst
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		process_need_cpu_us -= (curr_cpu.cfs_burst_us - cpu.cfs_quota_us)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># cpu.stat burst
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		cpu.stat.nr_bursts++
</span></span><span style="display:flex;"><span>		cpu.stat.burst_time += curr_cpu.cfs_burst_us - cpu.cfs_quota_us
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#00f">if</span> process_need_cpu_us &lt; 0 {
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># reset
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		curr_cpu.cfs_burst_us = cpu.cfs_quota_us
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># accumulate unused quota into curr_cpu.cfs_burst_us
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		curr_cpu.cfs_burst_us = min(cpu.cfs_burst_us, curr_cpu.cfs_burst_us - process_need_cpu_us)
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>	} <span style="color:#00f">else</span> <span style="color:#00f">if</span> process_need_cpu_us &gt; 0 {
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># cpu.stat
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		cpu.stat.nr_periods++
</span></span><span style="display:flex;"><span>		cpu.stat.nr_throttled++
</span></span><span style="display:flex;"><span>		cpu.stat.throttled_time += (cpu.cfs_period_us - cpu.cfs_quota_us) * 1000
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		<span style="color:#00f"># wait next period
</span></span></span><span style="display:flex;"><span><span style="color:#00f"></span>		sleep(cpu.cfs_period_us - max(cpu.cfs_quota_us, curr_cpu.cfs_burst_us))
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="workload">Workload</h3>
<h5 id="1-decrease-burst-workload-latency">1. Decrease Burst Workload Latency</h5>
<ul>
<li>increase both value but keep <em><strong>cpu.cfs_quota_us / cpu.cfs_period_us</strong></em> unchange, more tasks can be completed in one cpu.cfs_period_us</li>
<li>use <strong>cpu.cfs_burst_us</strong> (linux kernel &gt;= 5.14), usable only when there are some unused quota from previous periods (unused quota can be keep &lt;= cpu.cfs_burst_us - cpu.cfs_quota_us)</li>
<li>give up <strong>CFS</strong>, using <strong>cpuset</strong> (cpu affinity) to limit cpu usage [<a href="https://www.uber.com/blog/avoiding-cpu-throttling-in-a-containerized-environment/">uber blog - avoiding-cpu-throttling-in-a-containerized-environment</a>]</li>
</ul>
<h5 id="2-load-balancing-on-cloud-containers">2. Load Balancing On Cloud (Containers)</h5>
<ul>
<li><strong>least connections</strong> should be the first choice algorithm for load balancing gateway</li>
<li>when used <strong>least connections</strong> to do load balancing, <strong>the large ratio that the server oversolded, the less resource (cpu) usage show</strong> (because of <strong>cpu throttling</strong>)</li>
</ul>
<h3 id="dashboard--monitor--alert-metrics">Dashboard &amp;&amp; Monitor &amp;&amp; Alert Metrics</h3>
<h5 id="1-cfs-metrics">1. CFS Metrics</h5>
<ul>
<li><strong>cpu.stat.nr_periods</strong></li>
<li><strong>cpu.stat.nr_throttled</strong></li>
<li><strong>cpu.stat.throttled_time</strong></li>
<li><strong>cpu.stat.nr_bursts</strong></li>
<li><strong>cpu.stat.burst_time</strong></li>
</ul>
<p><strong>Get CPU Throttled Stat:</strong></p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>root@-:~# cat /sys/fs/cgroup/cpu/cpu.stat
</span></span><span style="display:flex;"><span>nr_periods 0
</span></span><span style="display:flex;"><span>nr_throttled 0
</span></span><span style="display:flex;"><span>throttled_time 0
</span></span></code></pre></div><h5 id="2-business-indicators">2. Business Indicators</h5>
<ul>
<li>P95/P99 lantency of given API</li>
<li>latency between all deployed servers</li>
</ul>
<p><strong>Warning:</strong></p>
<ul>
<li>the greater the <strong>cpu.stat.nr_throttled</strong>, the greater the tail latency</li>
</ul>
<h5 id="3-elk-dashboard-metrics">3. ELK Dashboard Metrics</h5>
<ul>
<li>using histogram displays the number of requests handled by each server over a specified time period</li>
<li>using histogram displays the average time about the handled requests of each server over a specified time period (average latency between servers)</li>
</ul>
<h2 id="references">References</h2>
<ol>
<li><a href="https://ieeexplore.ieee.org/document/4631872">Fairness and interactive performance of O(1) and CFS Linux kernel schedulers</a></li>
<li><a href="https://github.com/torvalds/linux/commit/512ac999d2755d2b7109e996a76b6fb8b888631d">linux kernel - cfs cpu throttling even in low cpu usage &lt; 4.18</a></li>
<li><a href="https://github.com/torvalds/linux/commit/f4183717b370ad28dd0c0d74760142b20e6e7931">linux kernel - cfs cpu.cfs_burst_us &gt;= 5.14</a></li>
<li><a href="https://lwn.net/ml/linux-kernel/20210202114038.64870-1-changhuaixin@linux.alibaba.com/">linux kernel - cpu.cfs_burst_us benchmark compare</a></li>
<li><a href="https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html">linux kernel - scheduler cfs</a></li>
<li><a href="https://www.uber.com/blog/vertical-cpu-scaling/">uber blog - vertical-cpu-scaling</a></li>
<li><a href="https://www.uber.com/blog/avoiding-cpu-throttling-in-a-containerized-environment/">uber blog - avoiding-cpu-throttling-in-a-containerized-environment</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/67577#issuecomment-466609030">kubernetes issue - CFS unnecessary throttling</a></li>
<li><a href="https://jaanhio.me/blog/kubernetes-cpu-requests-limits/">kubernetes - kubernetes-cpu-requests-limits</a></li>
</ol>

			</div>

			<div class="tags">
				
					
						<ul class="flat">
							
							<li><a href="/tags/paper-review">paper-review</a></li>
							
							<li><a href="/tags/linux">linux</a></li>
							
						</ul>
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2022  Â© Copyright chaosmatrix |  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>

<script>feather.replace()</script>
</body>
</html>
